{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e29f20",
   "metadata": {},
   "source": [
    "# Single character recognition model\n",
    "- Our goal with this model is to use convolutional neural networks to recognize a single character on an image, similarly to what is done with the famous MNIST handwritten-digit dataset. In fact, we will use a very similar dataset called EMNIST, and more specifically the \"balanced EMNIST\" which contains a total of 112799 images. In this version, although much smaller than the real dataset, all characters are balanced, so they appear which more or less the same frequency. We thought this would make better predictions on the segmented words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e825fdde",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD PACKAGES ###\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import random\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3cb12c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick check on the shapes:  (112799, 28, 28, 1) (112799, 1) (18799, 28, 28, 1) (18799, 1)\n"
     ]
    }
   ],
   "source": [
    "### LOAD DATASET ### (already split when downloading)\n",
    "\n",
    "train_file = pd.read_csv('data_2/emnist-balanced-train.csv')\n",
    "train_file = np.array(train_file)\n",
    "X_train = train_file[:,1:]\n",
    "X_train = X_train.reshape((X_train.shape[0],28,28,1))\n",
    "y_train = train_file[:,0]\n",
    "y_train = y_train.reshape((y_train.shape[0],1))\n",
    "\n",
    "test_file = pd.read_csv('data_2/emnist-balanced-test.csv')\n",
    "test_file = np.array(test_file)\n",
    "X_test = test_file[:,1:]\n",
    "X_test = X_test.reshape((X_test.shape[0],28,28,1))\n",
    "y_test = test_file[:,0]\n",
    "y_test = y_test.reshape((y_test.shape[0],1))\n",
    "\n",
    "print(\"Quick check on the shapes: \", X_train.shape, y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a8ba4b",
   "metadata": {},
   "source": [
    "### Parsing the data\n",
    "The dataset includes a mapping textfile which is used to map a character to its class label. Each class label (integers from 0 to n) is mapped to the ASCII representation of the character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a892c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 48, 1: 49, 2: 50, 3: 51, 4: 52, 5: 53, 6: 54, 7: 55, 8: 56, 9: 57, 10: 65, 11: 66, 12: 67, 13: 68, 14: 69, 15: 70, 16: 71, 17: 72, 18: 73, 19: 74, 20: 75, 21: 76, 22: 77, 23: 78, 24: 79, 25: 80, 26: 81, 27: 82, 28: 83, 29: 84, 30: 85, 31: 86, 32: 87, 33: 88, 34: 89, 35: 90, 36: 97, 37: 98, 38: 100, 39: 101, 40: 102, 41: 103, 42: 104, 43: 110, 44: 113, 45: 114, 46: 116}\n",
      "Label range:  0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "### PARSE DATA ###\n",
    "\n",
    "X_train = X_train.astype('float32')/255\n",
    "X_test = X_test.astype('float32')/255\n",
    "y_train = to_categorical(y_train.astype('uint8'))\n",
    "y_test = to_categorical(y_test.astype('uint8'))\n",
    "X_train, y_train = shuffle(X_train, y_train)\n",
    "\n",
    "with open('data_2/emnist-balanced-mapping.txt','r') as mapp:\n",
    "    d = dict()\n",
    "    for l in mapp.readlines():\n",
    "        d[int(l.split()[0])] = int(l.split()[1])\n",
    "\n",
    "print(d)\n",
    "print('Label range: ',np.min(y_train),np.max(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e3cdac",
   "metadata": {},
   "source": [
    "Let's display a few images to make sure the shuffling did not alter the labelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09d0d53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2178230f40>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAARlUlEQVR4nO3dfZBV9XkH8O/3LssuLK/Lu0gULSpSK+KKttSW6JgaJxM1jlHHpmRiQybVGdPaaa1OJ2aSTp00L5OZZtLBSCSN0TqjjMwUUyiaWCdVWZAIBBQEIgsLC6KCoMvuvU//2Guz6j3P2dy3c9nn+5nZubvn2bP34bLfPffe3/mdH80MIjL85bJuQETqQ2EXCUJhFwlCYRcJQmEXCWJEPe9sJFusFW31vEuRUN7DcZy0XpaqVRR2klcD+B6AJgA/NLP7ve9vRRsu5ZWV3KWIOF6wdYm1sp/Gk2wC8H0AnwRwPoBbSJ5f7s8Tkdqq5DX7QgA7zWyXmZ0E8CiAa6vTlohUWyVhnwlg76Cvu4rbPoDkUpKdJDv70FvB3YlIJSoJe6k3AT5y7q2ZLTOzDjPraEZLBXcnIpWoJOxdAGYN+vp0APsra0dEaqWSsK8HMIfkbJIjAdwMYFV12hKRait76M3M+kneAeC/MDD0ttzMtlatMxGpqorG2c1sNYDVVepFRGpIp8uKBKGwiwShsIsEobCLBKGwiwShsIsEUdf57NJ42Dyypj/f+k6WvW/FveVKTusGADRNneLuauP86y7w7Xfcev++lJNJM7iqs47sIkEo7CJBKOwiQSjsIkEo7CJBKOwiQWjobThg8hBTbt657q67b2x36/1tBbc+4kTyfQPAzJ+XP/S2b7E/9NY/2h++Mue3e/p5Pe6+l03Z4dZX75rn1s/82li3Xtiy3a3Xgo7sIkEo7CJBKOwiQSjsIkEo7CJBKOwiQSjsIkFonH0Y8MbS933DHwdfs+Cbbn18rsmtnyjk3fr/3PyRFcGG7PLWfW59dEpvTSUXLRrQTH/ffMoU1CWTfunWb736b9z6zO3J0bP+fnffcunILhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhKExtlPAWmXVN5108TE2toF/+LuO7NpdFk9vW+MP1yNG9reLPtnFzCq7H0BoNf6EmtH8r3uvg++1eHWH37lErd+5s+OuPVCjcbSPRWFneQeAMcA5AH0m5n/CIlIZqpxZP+4mR2uws8RkRrSa3aRICoNuwFYQ3IDyaWlvoHkUpKdJDv74L9OEpHaqfRp/CIz209yKoC1JLeb2bODv8HMlgFYBgDj2F7/Ba5EBECFR3Yz21+87QGwEsDCajQlItVXdthJtpEc+/7nAD4BYEu1GhOR6qrkafw0ACs5cM3yEQB+amY/q0pX8gFsbXHrJ6cmj9m252p7KkWv+ePFBSRfd/6E+XPhD+X9Y1Er/f039CbPpd90/Ax338ee/iO33r7Zv04Adr/s1zNQ9m+Cme0CcGEVexGRGtLQm0gQCrtIEAq7SBAKu0gQCrtIEJri2gicJZcBoH/+77n1L/7hs4m1UUxZ9hj+8NWvUlZcvunnX3bruTebE2sjjvv/7tbDfj3f6pYx/cX3Emsje467+87Zs9mtW69/6ncWU1jT6MguEoTCLhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTG2eshZWnhEadNd+u770y+JDIALJ240an6l2Pu7PV7+9tXbnTr53/9Dbee39edXCykXLjIkqfHDoW39LF/dsHwpCO7SBAKu0gQCrtIEAq7SBAKu0gQCrtIEAq7SBAaZ6+DXJu/LHLvnGlu/d4LnnTrE3PJY+lp89Xv3emPo7/7lN9bYWzKksznJ8/Fz53053zbni6/njKnXD5IR3aRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIDTOXg0VXvd996f9a7tfNfr1lAb8OeueOeMPufX/Xdzm1i/+wha3Prsl+ee/9t5Ud99Kl02e/MTWxFr+6FF33+Eo9chOcjnJHpJbBm1rJ7mW5I7i7cTatikilRrK0/iHAFz9oW13A1hnZnMArCt+LSINLDXsZvYsgCMf2nwtgBXFz1cAuK66bYlItZX7Bt00M+sGgOJt4osvkktJdpLs7IPOZRbJSs3fjTezZWbWYWYdzWip9d2JSIJyw36Q5AwAKN72VK8lEamFcsO+CsCS4udLAPhzMEUkc6nj7CQfAbAYwGSSXQC+CuB+AI+RvA3A6wD8SdHDXG6UP8594GK/Pmvefrc+hslrnKcZAf+68LdPfdqt3zBpnFu/cKR/3fixueRfsWNtO919R1/lLw7/0zM63Pr4185OrI3Y8Iq7b+HECbd+KkoNu5ndklC6ssq9iEgN6XRZkSAUdpEgFHaRIBR2kSAUdpEgaJaybG4VjWO7Xcrh9yZ+07xz3foFP/GHeW6f9Jxbn9nkX4q6icl/s/MVLnucpQL83823C++59e8fuSSxtvrbf+ruO+EnL7p1FBpz0ecXbB2O2pGSc391ZBcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJQpeSHgYqGUt/o/CuW9/V1+rWt/bOLPu+xzb59/1now+4dW+pagC4a9LGxNpDixa5+7av9M9tKBw75tYbkY7sIkEo7CJBKOwiQSjsIkEo7CJBKOwiQSjsIkFonL0KbPdet77mh/7Sw6sWX+DW75znX+65mclzq9OWRf6PZ/zeJm5LWRb5pZTx5nzynPTjZ45xd331a79w65+f0OnWZzjXAbj10ufdfTfMnufWuW2XW7c+/zLYWdCRXSQIhV0kCIVdJAiFXSQIhV0kCIVdJAiFXSQIXTe+DnKj/bnRufaJbj0/ZUL5932y363bni6/3tvr1/v9n+9Je1z2L53v1id/yu999dzHE2sv9frHuTv+6Q63Pm2Nf25F/16/t1qp6LrxJJeT7CG5ZdC2+0juI7mp+HFNNRsWkeobytP4hwBcXWL7d81sfvFjdXXbEpFqSw27mT0L4EgdehGRGqrkDbo7SL5cfJqf+KKT5FKSnSQ7++C//hOR2ik37D8AcDaA+QC6AXw76RvNbJmZdZhZRzNayrw7EalUWWE3s4NmljezAoAHACysblsiUm1lhZ3kjEFfXg9gS9L3ikhjSJ3PTvIRAIsBTCbZBeCrABaTnA/AAOwB8KXatXjqK5w4UVEdXfvKvu/GXEV8QNq/e/ov/bnyO2af5tb7zkv+188d6Z8f8NZc//yTyRvHu3VkNM7uSQ27md1SYvODNehFRGpIp8uKBKGwiwShsIsEobCLBKGwiwQR51LSuSa3zJx/yeRKpnJKAvqPef/YkW7dRjfywGLj0ZFdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJIhhM86edlniNz/zB279+HT/796sp95IrOW3vuLuK6WN+Njpbn3vl/3LmH3jgqfc+igmj9M/n3KFtAkpS1U3HX7brTfiWRk6sosEobCLBKGwiwShsIsEobCLBKGwiwShsIsEMWzG2Tl7llu/7K873fqNE190639x2l8l1s79esqSy2++6dZPZWz255w3nTYtsfb6Z/3/swcW/KtbvyjlctD9SB4r/7tXb3L3nfbf/qWg890H3Hoj0pFdJAiFXSQIhV0kCIVdJAiFXSQIhV0kCIVdJIjhM85+9LhbX3/oY249bZz9nz/1SGLtH1hqodvfOuvx99z6yL3Jc+UBIH+gx62jkLy8MFtb/H1nz3TLfZP86wTsvcL/+ZMvOZhY+7dz/HH0hS3+ssm5lF/f1/uTl4Q+vD55/B8Axu7f4NZPxXUEUo/sJGeRfIbkNpJbSd5Z3N5Oci3JHcVb/8wSEcnUUJ7G9wO4y8zmArgMwO0kzwdwN4B1ZjYHwLri1yLSoFLDbmbdZrax+PkxANsAzARwLYAVxW9bAeC6GvUoIlXwO71BR/JMABcBeAHANDPrBgb+IACYmrDPUpKdJDv7kHLhLxGpmSGHneQYAI8D+IqZHR3qfma2zMw6zKyjGSlvFolIzQwp7CSbMRD0h83sieLmgyRnFOszAKS8ZSwiWUodeiNJAA8C2GZm3xlUWgVgCYD7i7dP1qTDIUobnjq8/mK3vmraArf+j1OeT6xdfsO33H1/dKV/3/+5f55bP7D9IreOglMa4y9rfOvC5H8XAMwdtd+tXzHqN269vSn52Vwu5VjzYq9/OedfvDPXrS9f+/HE2jmPHnH3zfeddOunoqGMsy8C8DkAm0luKm67BwMhf4zkbQBeB3BjTToUkapIDbuZPQckXgXgyuq2IyK1otNlRYJQ2EWCUNhFglDYRYJQ2EWCGDZTXC3vjydP2OHvv3L7hW790+M3JtY6Wprcff9yYvK+AHDFmF+79a1n+NNQPWOb3nXrl7fu8/fP+b8io+hPgfV055OnoALAvTv/3K3v3TrdrZ+1Mnlqse3e6+47HOnILhKEwi4ShMIuEoTCLhKEwi4ShMIuEoTCLhIEzfzL9VbTOLbbpcxmolxutD8enJsyya13XZ+8vPCNX3ja3fe2Cf5y0eNz/rLHLfTHuvuRfI5Bn/nnH1TqWMG/pPKP3kqey+/NNweAOSvecuvc48+1zx8d8gWVho0XbB2O2pGSs1R1ZBcJQmEXCUJhFwlCYRcJQmEXCUJhFwlCYRcJIsw4e6W8cfr+Bee4++76TKtbn3LeYbd+6xnr3fqje5PHsg9sL7kq128515wfiuZ3/Gu7z1qTPJ9+xEv+RQYKx/1luOWjNM4uIgq7SBQKu0gQCrtIEAq7SBAKu0gQCrtIEKnj7CRnAfgxgOkYGJVdZmbfI3kfgC8COFT81nvMbLX3s07lcfZK5Nra/Hr7RLdemDTO3/+N5Hnb+Z5DibWBH17b8yxsGK5z3si8cfahLBLRD+AuM9tIciyADSTXFmvfNbNvVatREamdoazP3g2gu/j5MZLbAJS/RImIZOJ3es1O8kwAFwF4objpDpIvk1xOsuRzUZJLSXaS7OxDb2XdikjZhhx2kmMAPA7gK2Z2FMAPAJwNYD4GjvzfLrWfmS0zsw4z62hGS+Udi0hZhhR2ks0YCPrDZvYEAJjZQTPLm1kBwAMAFtauTRGpVGrYSRLAgwC2mdl3Bm2fMejbrgewpfrtiUi1DOXd+EUAPgdgM8lNxW33ALiF5HwABmAPgC/VoL9hIW2qZupUzpTVhSucpSpBDOXd+OcAlBq3c8fURaSx6Aw6kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEgFHaRIBR2kSAUdpEg6rpkM8lDAH4zaNNkAP56xdlp1N4atS9AvZWrmr2dYWZTShXqGvaP3DnZaWYdmTXgaNTeGrUvQL2Vq1696Wm8SBAKu0gQWYd9Wcb372nU3hq1L0C9lasuvWX6ml1E6ifrI7uI1InCLhJEJmEneTXJV0juJHl3Fj0kIbmH5GaSm0h2ZtzLcpI9JLcM2tZOci3JHcVbf73n+vZ2H8l9xcduE8lrMuptFslnSG4juZXkncXtmT52Tl91edzq/pqdZBOAVwFcBaALwHoAt5jZr+vaSAKSewB0mFnmJ2CQ/BMA7wD4sZn9fnHbNwEcMbP7i38oJ5rZ3zdIb/cBeCfrZbyLqxXNGLzMOIDrAHweGT52Tl+fRR0etyyO7AsB7DSzXWZ2EsCjAK7NoI+GZ2bPAjjyoc3XAlhR/HwFBn5Z6i6ht4ZgZt1mtrH4+TEA7y8znulj5/RVF1mEfSY+uKBRFxprvXcDsIbkBpJLs26mhGlm1g0M/PIAmJpxPx+Wuox3PX1omfGGeezKWf68UlmEvdRSUo00/rfIzBYA+CSA24tPV2VohrSMd72UWGa8IZS7/Hmlsgh7F4BZg74+HcD+DPooycz2F297AKxE4y1FffD9FXSLtz0Z9/P/GmkZ71LLjKMBHrsslz/PIuzrAcwhOZvkSAA3A1iVQR8fQbKt+MYJSLYB+AQabynqVQCWFD9fAuDJDHv5gEZZxjtpmXFk/Nhlvvy5mdX9A8A1GHhH/jUA92bRQ0JfZwH4VfFja9a9AXgEA0/r+jDwjOg2AJMArAOwo3jb3kC9/TuAzQBexkCwZmTU2x9j4KXhywA2FT+uyfqxc/qqy+Om02VFgtAZdCJBKOwiQSjsIkEo7CJBKOwiQSjsIkEo7CJB/B+dGU+IkaEzzgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### DISPLAY ONE IMAGE ###\n",
    "\n",
    "t = random.randint(0,100)\n",
    "print(chr(d[np.argmax(y_train[t])]))\n",
    "plt.imshow(X_train[t,:,:,0].T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29ffa61",
   "metadata": {},
   "source": [
    "The model we define is a convolutional neural network with 3 filter layers. This model is similar to what one would use for the MNIST dataset. Since there are a bit more classes than the latter, we though that the model would work well if we added some complexity by adding filters throughout the layers. The rest is similar to what we implemented in TD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f51b9527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(input_shape, num_classes):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding = 'valid'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64,activation =\"relu\"))\n",
    "    model.add(Dense(128,activation =\"relu\"))\n",
    "    model.add(Dense(num_classes,activation =\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer = Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7c2031f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(X_train.shape[1:], y_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c6a05b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x: np.array, y: np.array,\n",
    "                x_target: np.array, y_target: np.array,\n",
    "                batch_size: int = 32, epochs: int = 10):\n",
    "    e_stop = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=2)\n",
    "    model.fit(x, y, batch_size=batch_size, epochs=epochs, callbacks=[e_stop], validation_data=(x_target, y_target))\n",
    "    loss, accuracy = model.evaluate(x_target, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd241696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "882/882 [==============================] - 46s 51ms/step - loss: 0.8636 - accuracy: 0.7351 - val_loss: 0.4981 - val_accuracy: 0.8332\n",
      "Epoch 2/50\n",
      "882/882 [==============================] - 31s 36ms/step - loss: 0.4364 - accuracy: 0.8472 - val_loss: 0.4238 - val_accuracy: 0.8521\n",
      "Epoch 3/50\n",
      "882/882 [==============================] - 35s 40ms/step - loss: 0.3736 - accuracy: 0.8682 - val_loss: 0.4091 - val_accuracy: 0.8589\n",
      "Epoch 4/50\n",
      "882/882 [==============================] - 45s 51ms/step - loss: 0.3424 - accuracy: 0.8761 - val_loss: 0.3757 - val_accuracy: 0.8675\n",
      "Epoch 5/50\n",
      "882/882 [==============================] - 45s 51ms/step - loss: 0.3173 - accuracy: 0.8827 - val_loss: 0.3644 - val_accuracy: 0.8711\n",
      "Epoch 6/50\n",
      "882/882 [==============================] - 45s 51ms/step - loss: 0.2990 - accuracy: 0.8889 - val_loss: 0.3600 - val_accuracy: 0.8742\n",
      "Epoch 7/50\n",
      "882/882 [==============================] - 44s 50ms/step - loss: 0.2839 - accuracy: 0.8922 - val_loss: 0.3503 - val_accuracy: 0.8766\n",
      "Epoch 8/50\n",
      "882/882 [==============================] - 45s 51ms/step - loss: 0.2674 - accuracy: 0.8979 - val_loss: 0.3531 - val_accuracy: 0.8764\n",
      "Epoch 9/50\n",
      "882/882 [==============================] - 42s 48ms/step - loss: 0.2540 - accuracy: 0.9013 - val_loss: 0.3489 - val_accuracy: 0.8802\n",
      "Epoch 10/50\n",
      "882/882 [==============================] - 45s 51ms/step - loss: 0.2436 - accuracy: 0.9047 - val_loss: 0.3457 - val_accuracy: 0.8831\n",
      "Epoch 11/50\n",
      "882/882 [==============================] - 44s 50ms/step - loss: 0.2332 - accuracy: 0.9081 - val_loss: 0.3583 - val_accuracy: 0.8761\n",
      "Epoch 12/50\n",
      "882/882 [==============================] - 44s 50ms/step - loss: 0.2199 - accuracy: 0.9128 - val_loss: 0.3599 - val_accuracy: 0.8742\n",
      "Epoch 13/50\n",
      "882/882 [==============================] - 44s 50ms/step - loss: 0.2123 - accuracy: 0.9147 - val_loss: 0.3656 - val_accuracy: 0.8778\n",
      "Epoch 14/50\n",
      "882/882 [==============================] - 44s 50ms/step - loss: 0.2010 - accuracy: 0.9182 - val_loss: 0.3749 - val_accuracy: 0.8786\n",
      "Epoch 15/50\n",
      "882/882 [==============================] - 42s 47ms/step - loss: 0.1945 - accuracy: 0.9204 - val_loss: 0.3809 - val_accuracy: 0.8803\n",
      "Epoch 16/50\n",
      "882/882 [==============================] - 44s 50ms/step - loss: 0.1862 - accuracy: 0.9238 - val_loss: 0.3961 - val_accuracy: 0.8774\n",
      "Epoch 17/50\n",
      "882/882 [==============================] - 44s 50ms/step - loss: 0.1786 - accuracy: 0.9254 - val_loss: 0.3979 - val_accuracy: 0.8782\n",
      "Epoch 18/50\n",
      "882/882 [==============================] - 45s 50ms/step - loss: 0.1719 - accuracy: 0.9292 - val_loss: 0.4227 - val_accuracy: 0.8779\n",
      "Epoch 19/50\n",
      "882/882 [==============================] - 44s 50ms/step - loss: 0.1652 - accuracy: 0.9308 - val_loss: 0.4402 - val_accuracy: 0.8749\n",
      "Epoch 20/50\n",
      "882/882 [==============================] - 44s 50ms/step - loss: 0.1586 - accuracy: 0.9337 - val_loss: 0.4414 - val_accuracy: 0.8738\n",
      "Epoch 21/50\n",
      "882/882 [==============================] - 42s 47ms/step - loss: 0.1529 - accuracy: 0.9362 - val_loss: 0.4915 - val_accuracy: 0.8692\n",
      "Epoch 22/50\n",
      "349/882 [==========>...................] - ETA: 25s - loss: 0.1411 - accuracy: 0.9412"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-39fa03689a9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-b9ce635223e8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, x, y, x_target, y_target, batch_size, epochs)\u001b[0m\n\u001b[1;32m      3\u001b[0m                 batch_size: int = 32, epochs: int = 10):\n\u001b[1;32m      4\u001b[0m     \u001b[0me_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0me_stop\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2954\u001b[0m       (graph_function,\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2956\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model,X_train,y_train,X_test,y_test,128,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8025e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_char_v1/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('model_char_v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f47a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
